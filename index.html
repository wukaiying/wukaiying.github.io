<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>Kaiying</title>
  <meta property="og:title" content="Kaiying" />
  <meta name="twitter:title" content="Kaiying" />
  <meta name="author" content="kaiying"/>
  <meta property="og:site_name" content="Kaiying" />
  <meta property="og:url" content="https://wukaiying.github.io/" />
  <meta property="og:type" content="website" />
  <meta name="twitter:card" content="summary" />
  <meta name="generator" content="Hugo 0.61.0" />
  <link href="/index.xml" rel="alternate" type="application/rss+xml" title="Kaiying" />
  <link href="/index.xml" rel="feed" type="application/rss+xml" title="Kaiying" />

  <link rel="stylesheet" href="/css/style.css" media="all" />
  <link rel="stylesheet" href="/css/syntax.css" media="all" />
  <link rel="stylesheet" href="/css/custom.css" media="all" />

  <script src="/js/script.js"></script>
  <script src="/js/custom.js"></script>
  <script defer src="/js/fontawesome.js"></script>
</head>

<body>

<header class="site-header">
  <nav class="site-navi">
    <h1 class="site-title"><a href="/">Kaiying</a></h1>
    <ul class="site-navi-items">
      <li class="site-navi-item-categories"><a href="/categories/" title="Categories">Categories</a></li>
      <li class="site-navi-item-tags"><a href="/tags/" title="Tags">Tags</a></li>
      <li class="site-navi-item-archives"><a href="/archives/" title="Archives">Archives</a></li>
      <li class="site-navi-item-about"><a href="/about/" title="About">About</a></li>
    </ul>
  </nav>
</header>
<hr class="site-header-bottom">

  <div class="main" role="main">
    <section class="list home-list">
      <article class="article">
        <a href="/golang/go-plugin/" class="article-titles">
          <h2 class="article-title">golang 实现加载动态库</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>February 27, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/golang/">
              <i class="fas fa-folder"></i>
              golang
            </a>&nbsp;
          </li>
          <li class="article-meta-tags">
            <a href="/tags/go/">
              <i class="fas fa-tag"></i>
              go
            </a>&nbsp;
          </li>
          <li class="article-meta-tags">
            <a href="/tags/plugin/">
              <i class="fas fa-tag"></i>
              plugin
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          golang开发中需要用到插件动态加载技术，需要主程序动态加载一些功能模块，不需要修改主程序。相比于java ,java 可以通过加载class文件方式来实现模块加载，而golang通常都是单个二进制文件。 go-plugin则使用另外一种方式实现插件加载，主进程和插件进程是两个独立的进程，二者通过rpc/grpc的方式进行通信， 从而实现主进程调用插件进程。
其次，golang也原生提供一种插件模块加载机制plugins，下面依次进行介绍。
go-plugin 项目地址https://github.com/hashicorp/go-plugin
特征  插件是Go接口的实现：这让插件的编写、使用非常自然。对于插件的作者来说，他只需要实现一个Go接口即可；对于插件的用户来说，他只需要调用一个Go接口即可。go-plugin会处理好本地调用转换为gRPC调用的所有细节 跨语言支持：插件可以基于任何主流语言编写，同样可以被任何主流语言消费 支持复杂的参数、返回值：go-plugin可以处理接口、io.Reader/Writer等复杂类型 双向通信：为了支持复杂参数，宿主进程能够将接口实现发送给插件，插件也能够回调到宿主进程 内置日志系统：任何使用log标准库的的插件，都会将日志信息传回宿主机进程。宿主进程会在这些日志前面加上插件二进制文件的路径，并且打印日志 协议版本化：支持一个简单的协议版本化，增加版本号后可以基于老版本协议的插件无效化。当接口签名变化时应当增加版本 标准输出/错误同步：插件以子进程的方式运行，这些子进程可以自由的使用标准输出/错误，并且打印的内容会被自动同步到宿主进程，宿主进程可以为同步的日志指定一个io.Writer TTY Preservation：插件子进程可以链接到宿主进程的stdin文件描述符，以便要求TTY的软件能正常工作 宿主进程升级：宿主进程升级的时候，插件子进程可以继续允许，并在升级后自动关联到新的宿主进程 加密通信：gRPC信道可以加密 完整性校验：支持对插件的二进制文件进行Checksum 插件崩溃了，不会导致宿主进程崩溃 容易安装：只需要将插件放到某个宿主进程能够访问的目录即可  用法 这里我们通过一个实例来体验一下go-plugin插件开发。我们需要完成的功能是，主程序暴露了两个方法，插件模块去实现这两个方法，然后主程序加载插件完成功能实现。 最终达成的效果是通过Put方法设置一个key/value对，通过get方法获取key对应的值。
Put(key string, value []byte) error Get(key string) ([]byte, error) ([]byte, error) 新建项目 这里我先将完整项目目录结构列出来
. ├── Makefile ├── cmd │ ├── cmd │ ├── kv_wky │ └── main.go ├── pkg │ ├── plugins │ │ └── proto │ │ ├── plugin.pb.go │ │ └── plugin.proto │ └── shared │ ├── grpc.go │ └── plugin.go └── pluginclient ├── main.go └── pluginclient 定义proto 新建pkg/plugins/proto/plugin.proto文件，并生成plugin.pb.go
syntax = &#34;proto3&#34;;package proto;message GetRequest { string key = 1;}message GetResponse { bytes value = 1;}message PutRequest { string key = 1; bytes value = 2;}message Empty {}service KV { rpc Get(GetRequest) returns (GetResponse); rpc Put(PutRequest) returns (Empty);} 定义对外暴露的插件接口 新建pkg/shared/plugin.
        </div>
        <div class="article-readmore"><a href="/golang/go-plugin/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/k8s/kubelet-create-pod-lifecycle/" class="article-titles">
          <h2 class="article-title">Kubelet 创建pod流程分析</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>April 28, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/k8s/">
              <i class="fas fa-folder"></i>
              k8s
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          前言 上一节我们分析了kubelet启动的基本流程，这一节我们分析一下当有新的pod分配到当前节点时，kubelet如何创建一个pod
syncLoop 上一节最后我们分析到kl.syncLoop(updates, kl)，是kubelet里面一个主循环逻辑，看一下它的具体实现： 它从不同的管道（文件、URL 和 apiserver）监听变化，并把它们汇聚起来。 当有新的变化发生时，它会调用对应的处理函数，保证 pod 处于期望的状态。 如果 pod 没有变化，它也会定期保证所有的容器和最新的期望状态保持一致。这个方法是 for 循环，不会退出。
func (kl *Kubelet) syncLoop(updates &lt;-chan kubetypes.PodUpdate, handler SyncHandler) { klog.Info(&#34;Starting kubelet main sync loop.&#34;) syncTicker := time.NewTicker(time.Second) defer syncTicker.Stop() housekeepingTicker := time.NewTicker(housekeepingPeriod) defer housekeepingTicker.Stop() plegCh := kl.pleg.Watch() const ( base = 100 * time.Millisecond max = 5 * time.Second factor = 2 ) duration := base for { if err := kl.runtimeState.runtimeErrors(); err != nil { klog.Infof(&#34;skipping pod synchronization - %v&#34;, err) // exponential backoff 	time.Sleep(duration) duration = time.Duration(math.Min(float64(max), factor*float64(duration))) continue } // reset backoff if we have a success 	duration = base kl.
        </div>
        <div class="article-readmore"><a href="/k8s/kubelet-create-pod-lifecycle/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/k8s/kube-scheduler-priority-source-read/" class="article-titles">
          <h2 class="article-title">Kube Scheduler 优选策略源码分析</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>April 24, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/k8s/">
              <i class="fas fa-folder"></i>
              k8s
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          版本环境   kubernetes版本：kubernetes:v1.16.0
  go环境：go version go1.13.4 darwin/amd64
  前言 预选阶段完成后，进入优选阶段，将需要调度的Pod列表和Node列表传入各种优选算法进行打分，最终整合成结果集HostPriorityList
//pkg/scheduler/core/generic_scheduler.go:189 // Schedule tries to schedule the given pod to one of the nodes in the node list. // If it succeeds, it will return the name of the node. // If it fails, it will return a FitError error with reasons. func (g *genericScheduler) Schedule(pod *v1.Pod, pluginContext *framework.PluginContext) (result ScheduleResult, err error) { ... trace.Step(&#34;Basic checks done&#34;) startPredicateEvalTime := time.Now() filteredNodes, failedPredicateMap, filteredNodesStatuses, err := g.findNodesThatFit(pluginContext, pod) if err != nil { return result, err } // Run &#34;postfilter&#34; plugins. 	postfilterStatus := g.framework.RunPostFilterPlugins(pluginContext, pod, filteredNodes, filteredNodesStatuses) if !
        </div>
        <div class="article-readmore"><a href="/k8s/kube-scheduler-priority-source-read/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/k8s/kubelet-structure/" class="article-titles">
          <h2 class="article-title">Kubelet 架构分析</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>April 23, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/k8s/">
              <i class="fas fa-folder"></i>
              k8s
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          版本环境   kubernetes版本：kubernetes:v1.16.0
  go环境：go version go1.13.4 darwin/amd64
  前言 kubelet是k8s集群中节点的代理人，通过watch api server，来处理发送给本节点的任务，看一下官方对kubelet的描述：
The kubelet is the primary &quot;node agent&quot; that runs on each node. It can register the node with the apiserver using one of: the hostname; a flag to override the hostname; or specific logic for a cloud provider. The kubelet works in terms of a PodSpec. A PodSpec is a YAML or JSON object that describes a pod. The kubelet takes a set of PodSpecs that are provided through various mechanisms (primarily through the apiserver) and ensures that the containers described in those PodSpecs are running and healthy.
        </div>
        <div class="article-readmore"><a href="/k8s/kubelet-structure/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/k8s/kube-scheduler-source-code-read/" class="article-titles">
          <h2 class="article-title">K8S Scheduler 源码分析</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>April 22, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/k8s/">
              <i class="fas fa-folder"></i>
              k8s
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          版本环境   kubernetes版本：kubernetes:v1.16.0
  go环境：go version go1.13.4 darwin/amd64
  前言 kube-scheduler 是master节点中重要的组件之一，它同watch接口监听api server中需要调度的pod，然后通过其预选，优选算法来确定pod需要被调度到哪个节点上去。
看一下官方对scheduler 调度流程的描述：The Kubernetes Scheduler
主要步骤如下：
 首先通过预选阶段过滤掉不合适的节点，例如根据podSpec中对系统资源的需求，会计算出所有节点剩余的资源是否可以满足pod需求，如果不满足则该节点会被抛弃。 其次通过预选阶段的节点，会再次进行优选。比如在满足pod资源需求的基础上，会优选出当前负载最小节点，保证每个集群节点资源被均衡使用。 最后选择打分最高的节点作为目标节点，如果得分相同则会随机选择一个，进行调度。  For given pod: +---------------------------------------------+ | Schedulable nodes: | | | | +--------+ +--------+ +--------+ | | | node 1 | | node 2 | | node 3 | | | +--------+ +--------+ +--------+ | | | +-------------------+-------------------------+ | | v +-------------------+-------------------------+ Pred. filters: node 3 doesn't have enough resource +-------------------+-------------------------+ | | v +-------------------+-------------------------+ | remaining nodes: | | +--------+ +--------+ | | | node 1 | | node 2 | | | +--------+ +--------+ | | | +-------------------+-------------------------+ | | v +-------------------+-------------------------+ Priority function: node 1: p=2 node 2: p=5 +-------------------+-------------------------+ | | v select max{node priority} = node 2 入口 scheduler使用cobra创建命令行客户端，进入NewSchedulerCommand
        </div>
        <div class="article-readmore"><a href="/k8s/kube-scheduler-source-code-read/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/k8s/replicaset-source-code-read/" class="article-titles">
          <h2 class="article-title">Replica Set Controller 源码分析</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>April 21, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/k8s/">
              <i class="fas fa-folder"></i>
              k8s
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          版本环境 kubernetes版本：kubernetes:v1.16.0
go环境：go version go1.13.4 darwin/amd64
前言 前面文章已经总结到，deployment controller通过replicaset来控制pod的创建和删除，进而实现更高级操作例如，滚动更新，回滚等。本文继续从源码角度 分析replicaset controller如何控制pod的创建和删除。
在分析源码前先考虑一下 replicaset 的使用场景，在平时的操作中其实我们并不会直接操作 replicaset，replicaset 也仅有几个简单的操作，创建、删除、更新等。
源码分析 入口 我们在上一篇文章中也说道controller manager是所有k8s 资源controller的管控中心，包含的主要逻辑就是高可用选择leader，然后 遍历所有的controllers,对每一个controller进行初始化并启动，也就是说只要集群启动，所有的controller也会都启动起来，开始list-watch api server，来准备创建资源。
cmd/kube-controller-manager/app/controllermanager.go:386 func NewControllerInitializers(loopMode ControllerLoopMode) map[string]InitFunc { controllers := map[string]InitFunc{} controllers[&#34;endpoint&#34;] = startEndpointController controllers[&#34;endpointslice&#34;] = startEndpointSliceController ... controllers[&#34;deployment&#34;] = startDeploymentController controllers[&#34;replicaset&#34;] = startReplicaSetController } 接下来进入startReplicaSetController, 发现通过NewReplicaSetController初始化了ReplicaSetController，并并调用run方法启动controller。
cmd/kube-controller-manager/app/apps.go:69 func startReplicaSetController(ctx ControllerContext) (http.Handler, bool, error) { if !ctx.AvailableResources[schema.GroupVersionResource{Group: &#34;apps&#34;, Version: &#34;v1&#34;, Resource: &#34;replicasets&#34;}] { return nil, false, nil } go replicaset.NewReplicaSetController( ctx.InformerFactory.Apps().V1().ReplicaSets(), ctx.InformerFactory.Core().V1().Pods(), ctx.ClientBuilder.ClientOrDie(&#34;replicaset-controller&#34;), replicaset.BurstReplicas, ).Run(int(ctx.ComponentConfig.ReplicaSetController.ConcurrentRSSyncs), ctx.Stop) return nil, true, nil } 我们先分析NewReplicaSetController看一下初始化ReplicaSetController的具体步骤：发现他会监听rs的add,update,delete操作，和pod的add,update,delete操作。 当这两种资源发送变化时，将key(name+namespace)添加到queue队列中去。
//pkg/controller/replicaset/replica_set.go:126  func NewBaseController(rsInformer appsinformers.ReplicaSetInformer, podInformer coreinformers.PodInformer, kubeClient clientset.Interface, burstReplicas int, gvk schema.GroupVersionKind, metricOwnerName, queueName string, podControl controller.
        </div>
        <div class="article-readmore"><a href="/k8s/replicaset-source-code-read/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/k8s/controller-manager-source-code-read/" class="article-titles">
          <h2 class="article-title">K8S Controller Manager 源码分析</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>April 19, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/k8s/">
              <i class="fas fa-folder"></i>
              k8s
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          版本环境   kubernetes版本：kubernetes:v1.16.0
  go环境：go version go1.13.4 darwin/amd64
  前言 Controller Manager内部包含Replication Controller、Node Controller、 ResourceQuota Controller、Namespace Controller、ServiceAccount Controller、Token Controller、Service Controller及Endpoint Controller这8种Controller， 每个Controller，它们通过API Server提供的（List-Watch）接口实时监控集群中特定资源的状态变化，当发生各种故障 导致某资源对象的状态发生变化时，Controller会尝试将其状态调整为期望的状态。
代码总体解析 入口 # cmd/kube-controller-manager/controller-manager.go func main() { rand.Seed(time.Now().UnixNano()) command := app.NewControllerManagerCommand() logs.InitLogs() defer logs.FlushLogs() if err := command.Execute(); err != nil { os.Exit(1) } } 进入NewControllerManagerCommand 函数，可以看到新建ControllerManager需要两步 启动参数配置，及Run函数，进入Run函数。
func NewControllerManagerCommand() *cobra.Command { s, err := options.NewKubeControllerManagerOptions() if err != nil { klog.Fatalf(&#34;unable to initialize command options: %v&#34;, err) } cmd := &amp;cobra.Command{ Use: &#34;kube-controller-manager&#34;, Run: func(cmd *cobra.Command, args []string) { verflag.PrintAndExitIfRequested() utilflag.PrintFlags(cmd.Flags()) c, err := s.Config(KnownControllers(), ControllersDisabledByDefault.List()) if err != nil { fmt.Fprintf(os.Stderr, &#34;%v\n&#34;, err) os.
        </div>
        <div class="article-readmore"><a href="/k8s/controller-manager-source-code-read/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/k8s/api-server-source-read/" class="article-titles">
          <h2 class="article-title">K8S Api Server 源码分析</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>April 13, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/k8s/">
              <i class="fas fa-folder"></i>
              k8s
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          版本环境   kubernetes版本：kubernetes:v1.16.0
  go环境：go version go1.13.4 darwin/amd64
  Api Server架构 kubernetes api server 提供了增删改查，list,watch各类资源的接口，对请求进行验证，鉴权及admission controller, 请求成功后将结果更新到后端存储etcd（也可以是其他存储）中。
api server 架构从上到下可以分为以下几层：
1.Api层，主要包含三种api core api: 主要在/api/v1下
分组api: 其path为/apis/$NAME/$VERSION
暴露系统状态的api: 如/metrics,/healthz,/logs,/openapi等
$ curl -k https://127.0.0.1:56521 { &#34;paths&#34;: [ &#34;/api&#34;, &#34;/api/v1&#34;, &#34;/apis&#34;, &#34;/apis/&#34;, &#34;/apis/admissionregistration.k8s.io&#34;, &#34;/apis/admissionregistration.k8s.io/v1beta1&#34;, ... &#34;/healthz&#34;, &#34;/healthz/autoregister-completion&#34;, &#34;/healthz/etcd&#34;, ... &#34;/logs&#34;, &#34;/metrics&#34;, &#34;/openapi/v2&#34;, &#34;/swagger-2.0.0.json&#34;, &#34;/swaggerapi&#34;, &#34;/version&#34; 2.访问控制层 当用户访问api接口时，访问控制层将会做如下校验：
对用户进行身份校验(authentication)&ndash;&gt; 校验用户对k8s资源对象访问权限(authorization) &ndash;&gt; 根据配置的资源访问许可逻辑(admission control)，判断是否访问。
下面分别对这三种校验方式进行说明：
2.1 Authentication 身份校验 k8s提供了三种客户端身份校验方式：https双向证书认证，http token方式认证， http base 认证也就是用户名密码方式
a. 基于CA根证书签名的双向数字证书认证
client和server向CA机构申请证书
client-&gt;server，server下发服务端证书，client利用证书验证server是否合法
client发送客户端证书给server，server利用证书校验client是否合法
client和server利用随机密钥加密消息，然后通信
apiserver启动的时候通过&ndash;client-ca-file=XXXX配置签发client证书的CA，当client发送证书过来时，apiserver使用CA验证，如果证书合法，则可进行通信。
这种方式的优点是安全，缺点是无法撤销用户证书，创建集群就绑定了证书。
$ k get pods kube-apiserver-kind-control-plane -n kube-system -o yaml - command: - kube-apiserver - --authorization-mode=Node,RBAC - --advertise-address=172.17.0.2 - --allow-privileged=true - --client-ca-file=/etc/kubernetes/pki/ca.crt b.
        </div>
        <div class="article-readmore"><a href="/k8s/api-server-source-read/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/k8s/dns-problem/" class="article-titles">
          <h2 class="article-title">CoreDNS生产案：pod出现dns解析大量失败的问题</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>March 31, 2020</time></li>
          <li class="article-meta-categories">
            <a href="/categories/k8s/">
              <i class="fas fa-folder"></i>
              k8s
            </a>&nbsp;
          </li>
        </ul>
        <div class="article-content">
          问题 收到阿里云K8S集群监控告警：
CoreDNS 5分钟内NXDOMAIN响应百分比大于50% k8s.coredns.response[aliyun,172.22.82.25:9153,NXDOMAIN]
是coredns的172.22.82.25的这个pod出现dns解析大量失败的问题。（解析成功的日志是NOERROR，解析失败是：NXDMAIN）
分析 首先是查看这个coredns pod的日志：
[root@iZbp16er8wkobo2a165ekzZ ~]# kubectl get pods -n kube-system -o wide | grep coredns |grep 172.22.82.25 coredns-57dc86754b-9schh 1/1 Running 0 17d 172.22.82.25 cn-hangzhou.xxx.xxx.xxx.xxx &lt;none&gt;[root@iZbp16er8wkobo2a165ekzZ ~]# kubectl logs -n kube-system coredns-57dc86754b-9schh | tail -10 2020-03-05T13:06:29.745Z [INFO] 172.22.0.66:54106 - 24311 &quot;A IN metrics.cn-hangzhou.aliyuncs.com. udp 50 false 512&quot; NOERROR qr,rd,ra 190 0.00003395s 2020-03-05T13:06:29.745Z [INFO] 172.22.0.66:56730 - 20278 &quot;AAAA IN metrics.cn-hangzhou.aliyuncs.com. udp 50 false 512&quot; NOERROR qr,rd,ra 232 0.000072002s 2020-03-05T13:06:29.748Z [INFO] 172.22.0.66:41047 - 53211 &quot;AAAA IN metrics.cn-hangzhou.aliyuncs.com.kube-system.svc.cluster.local. udp 80 false 512&quot; NXDOMAIN qr,rd,ra 173 0.00004196s 2020-03-05T13:06:29.748Z [INFO] 172.22.0.66:40581 - 40714 &quot;A IN metrics.cn-hangzhou.aliyuncs.com.kube-system.svc.cluster.local. udp 80 false 512&quot; NXDOMAIN qr,rd,ra 173 0.
        </div>
        <div class="article-readmore"><a href="/k8s/dns-problem/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
      <article class="article">
        <a href="/post/my-second/" class="article-titles">
          <h2 class="article-title">My Second</h2>
          
        </a>
        <ul class="article-meta">
          <li class="article-meta-date"><time>February 11, 2020</time></li>
        </ul>
        <div class="article-content">
          
        </div>
        <div class="article-readmore"><a href="/post/my-second/">Read more...</a></div>
        <div class="article-floatclear"></div>
      </article>
    </section>
    

<ul class="pagination">
    
    <li class="page-item">
        <a href="/" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item disabled">
    <a  class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/page/2/">2</a></li>
    
    
    <li class="page-item">
    <a href="/page/2/" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="/page/2/" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>


  </div>



<div class="site-footer">
  <div class="copyright">&copy; Copyright 2017 Your name</div>
  <ul class="site-footer-items">
    <li class="site-footer-item-rsslink">
      <a href="/index.xml" type="application/rss+xml" target="_blank" title="RSS">
        <i class="fas fa-rss"></i>
      </a>
    </li>
    <li class="site-footer-item-about"><a href="/about/" title="About">About</a></li>
  </ul>
  <div class="powerdby">
    Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://github.com/taikii/whiteplain">Whiteplain</a>
  </div>
</div>


</body>
</html>
